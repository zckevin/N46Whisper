{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title **download**\n",
        "\n",
        "download_url = \"\"  # @param {type:\"string\"}\n",
        "global download_path\n",
        "download_path = \"/tmp/1.aac\"\n",
        "\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve(download_url, download_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title **通用参数/Required settings:**\n",
        "\n",
        "\n",
        "# @markdown **【IMPORTANT】:**<font size=\"2\">Select uploaded file type.\n",
        "# @markdown **</br>【重要】:** 选择上传的文件类型(视频-video/音频-audio）</font>\n",
        "\n",
        "# encoding:utf-8\n",
        "file_type = \"audio\"  # @param [\"audio\",\"video\"]\n",
        "\n",
        "# @markdown <font size=\"2\">Model size will affect the processing time and transcribe quality.\n",
        "# @markdown <br/>The default source language is Japanese.Please input your own source language if applicable.Use two letter language code， e.g.  'en', 'ja'...\n",
        "# @markdown <br/>模型大小将影响转录时间和质量, **默认使用稳定的large-v2模型以节省时间**\n",
        "# @markdown <br/>默认识别语言为日语，若使用其它语言的视频请自行输入即可。请注意：使用两字母语言代码如'en'，'ja'\n",
        "# @markdown <br/>【请注意】：large-v3在某些情况下可能未必优于large-v2或更早的模型，请用户自行选择\n",
        "\n",
        "model_size = \"large-v2\"  # @param [\"base\",\"small\",\"medium\", \"large-v1\",\"large-v2\",\"large-v3\"]\n",
        "language = \"ja\"  # @param {type:\"string\"}\n",
        "\n",
        "# @markdown <font size=\"2\">默认只导出ass，若需要srt则选择Yes</font>\n",
        "# @markdown <br/><font size=\"2\">导出时浏览器会弹出允许同时下载多个文件的请求，需要同意\n",
        "export_srt = \"No\"  # @param [\"No\",\"Yes\"]\n",
        "\n",
        "\n",
        "@title **其他选项/Advanced settings**\n",
        "\n",
        "# @markdown <font size=\"2\">Option for split line text by spaces. The splited lines all use the same time stamp, with 'adjust_required' label as remark for manual adjustment.\n",
        "# @markdown <br/>将存在空格的单行文本分割为多行（多句）。分割后的若干行均临时采用相同时间戳，且添加了adjust_required标记提示调整时间戳避免叠轴\n",
        "# @markdown <br/>普通分割（Modest): 当空格后的文本长度超过5个字符，则另起一行\n",
        "# @markdown <br/>全部分割（Aggressive): 只要遇到空格即另起一行\n",
        "# @markdown <br/>标点分割（Punctuation): 只要遇到句号即另起一行，在未来可能添加更加智能的标点分割方法\n",
        "is_split = \"No\"  # @param [\"No\",\"Yes\"]\n",
        "split_method = \"Modest\"  # @param [\"Modest\",\"Aggressive\", \"Punctuation\"]\n",
        "# @markdown <font size=\"2\">Please contact us if you want to have your sub style integrated.\n",
        "# @markdown <br/>当前支持生成字幕格式：\n",
        "# @markdown <br/><li>ikedaCN - 特蕾纱熊猫观察会字幕组\n",
        "# @markdown <br/><li>sugawaraCN - 坂上之月字幕组\n",
        "# @markdown <br/><li>kaedeCN - 三番目の枫字幕组\n",
        "# @markdown <br/><li>taniguchiCN - 泪痣愛季応援団\n",
        "# @markdown <br/><li>asukaCN - 暗鳥其实很甜字幕组\n",
        "sub_style = \"default\"  # @param [\"default\", \"ikedaCN\", \"kaedeCN\",\"sugawaraCN\",\"taniguchiCN\",\"asukaCN\"]\n",
        "\n",
        "# @markdown **使用VAD过滤/Use VAD filter**\n",
        "\n",
        "# @markdown <font size=\"2\">使用[Silero VAD model](https://github.com/snakers4/silero-vad)以检测并过滤音频中的无声段落（推荐小语种使用）\n",
        "# @markdown <br/>[WARNING] Use VAD filter have pros and cons, please carefully select this option accroding to your own audio content.\n",
        "# @markdown <br/>【注意】使用VAD filter有优点亦有缺点，请用户自行根据音频内容决定是否启用. [关于VAD filter](https://github.com/Ayanaminn/N46Whisper/blob/main/FAQ.md)\n",
        "\n",
        "\n",
        "is_vad_filter = \"False\" # @param [\"True\", \"False\"]\n",
        "# @markdown  <font size=\"2\"> *  The default <font size=\"3\">  ```min_silence_duration``` <font size=\"2\"> is set at 1000 ms in N46Whisper\n",
        "\n",
        "# @markdown **设置Beam Size**\n",
        "\n",
        "# @markdown <font size=\"2\">Beam Size数值越高，在识别时探索的路径越多，这在一定范围内可以帮助提高识别准确性，但是相对的VRAM使用也会更高. 同时，Beam Size在超过5-10后有可能降低精确性，详情请见https://arxiv.org/pdf/2204.05424.pdf\n",
        "# @markdown <br/> 默认设置为 5\n",
        "set_beam_size = 5 #@param\n",
        "\n",
        "# @markdown <font size=\"2\">在不设置Beam Size时，Whisper将会使用贪心解码，这在一定程度上可能与英语等其他语言的换行功能有联系，详情请见https://github.com/Ayanaminn/N46Whisper/issues/46\n",
        "# @markdown <br/> 默认设置为 false\n",
        "beam_size_off = False # @param {type:\"boolean\"}\n",
        "\n",
        "# # @markdown <font size=\"2\">设置此参数为True将在代码执行完毕后自动断开Colab的连接。这有助于在长时间运行的任务完成后释放资源。请注意，断开连接后，所有未保存的数据将丢失。</font>\n",
        "# # @markdown <br/> 默认设置为 False\n",
        "# auto_disconnect = True #@param {type:\"boolean\"}\n",
        "\n",
        "# # 以下代码用于断开连接\n",
        "# from IPython.display import Javascript\n",
        "\n",
        "# def disconnect_runtime():\n",
        "#     if auto_disconnect:\n",
        "#         display(Javascript('google.colab.kernel.disconnect();'))\n",
        "#         print(\"已经自动断开连接。\")\n",
        "#     else:\n",
        "#         print(\"自动断开连接功能已关闭。\")行Whisper/Run Whisper**\n",
        "# Hugging Face Hub\n",
        "# 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\n",
        "\n",
        "#@markdown 完成后ass文件将自动下载到本地/ass file will be auto downloaded after finish.\n",
        "! pip install ffmpeg\n",
        "! wget https://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@raw.githubusercontent.com/Ayanaminn/N46Whisper/main/srt2ass.py\n",
        "! pip install pysubs2\n",
        "! pip install faster-whisper\n",
        "# ! pip install nest_asyncio\n",
        "import torch\n",
        "# import nest_asyncio\n",
        "from faster_whisper import WhisperModel\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "clear_output()\n",
        "print('语音识别库配置完毕，将开始转换')\n",
        "import os\n",
        "import ffmpeg\n",
        "import subprocess\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import pandas as pd\n",
        "import requests\n",
        "from urllib.parse import quote_plus\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import pysubs2\n",
        "import gc\n",
        "import zipfile\n",
        "import asyncio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ** run **\n",
        "\n",
        "# Enable nested asyncio in Jupyter Notebook\n",
        "# nest_asyncio.apply()\n",
        "\n",
        "# assert file_name != \"\"\n",
        "# assert language != \"\"\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "file_names = [download_path]\n",
        "file_basenames = []\n",
        "\n",
        "sys.path.append('/drive/content')\n",
        "if not os.path.exists(file_names[0]):\n",
        "  raise ValueError(f\"No {file_names[0]} found in current path.\")\n",
        "else:\n",
        "    try:\n",
        "        for i in range(len(file_names)):\n",
        "          file_basenames.append(Path(file_names[i]).stem)\n",
        "        output_dir = Path(file_names[0]).parent.resolve()\n",
        "        # print(file_basename)\n",
        "        # print(output_dir)\n",
        "    except Exception as e:\n",
        "        print(f'error: {e}')\n",
        "\n",
        "\n",
        "clear_output()\n",
        "print('加载模型 Loading model...')\n",
        "\n",
        "model = WhisperModel(model_size)\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "for i in range(len(file_names)):\n",
        "  file_name = file_names[i]\n",
        "  #Transcribe\n",
        "  file_basename = file_basenames[i]\n",
        "  if file_type == \"video\":\n",
        "    print('提取音频中 Extracting audio from video file...')\n",
        "    os.system(f'ffmpeg -i {file_name} -f mp3 -ab 192000 -vn {file_basename}.mp3')\n",
        "    print('提取完毕 Done.')\n",
        "  # print(file_basename)\n",
        "  tic = time.time()\n",
        "  clear_output()\n",
        "  print('识别中 Transcribe in progress...')\n",
        "\n",
        "  if beam_size_off:\n",
        "    segments, info = model.transcribe(audio = f'{file_name}',\n",
        "                                          language=language,\n",
        "                                          vad_filter=is_vad_filter,\n",
        "                                          vad_parameters=dict(min_silence_duration_ms=1000))\n",
        "  else:\n",
        "    segments, info = model.transcribe(audio = f'{file_name}',\n",
        "                                          beam_size=set_beam_size,\n",
        "                                          language=language,\n",
        "                                          vad_filter=is_vad_filter,\n",
        "                                          vad_parameters=dict(min_silence_duration_ms=1000))\n",
        "\n",
        "  # segments is a generator so the transcription only starts when you iterate over it\n",
        "  # to use pysubs2, the argument must be a segment list-of-dicts\n",
        "  total_duration = round(info.duration, 2)  # Same precision as the Whisper timestamps.\n",
        "  results= []\n",
        "  with tqdm(total=total_duration, unit=\" seconds\") as pbar:\n",
        "      for s in segments:\n",
        "          segment_dict = {'start':s.start,'end':s.end,'text':s.text}\n",
        "          results.append(segment_dict)\n",
        "          segment_duration = s.end - s.start\n",
        "          pbar.update(segment_duration)\n",
        "\n",
        "\n",
        "  #Time comsumed\n",
        "  toc = time.time()\n",
        "  print('识别完毕 Done')\n",
        "  print(f'Time consumpution {toc-tic}s')\n",
        "\n",
        "  subs = pysubs2.load_from_whisper(results)\n",
        "  srt_filename = file_basename + '.srt'\n",
        "  subs.save(srt_filename)\n",
        "\n",
        "  from srt2ass import srt2ass\n",
        "  ass_filename  = srt2ass(srt_filename, sub_style, is_split,split_method)\n",
        "  print('ASS subtitle saved as: ' + ass_filename )\n",
        "\n",
        "  if i+1 ==1:\n",
        "    #一个文件则直接下载\n",
        "    files.download(ass_filename )\n",
        "  else:\n",
        "    # 用压缩包来处理所有下载，避免多个下载触发浏览器限制，必须要跟用户交互才能继续\n",
        "    zip_filename = file_basename+\".zip\"\n",
        "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "      if export_srt == 'Yes':\n",
        "          zipf.write(srt_filename)\n",
        "      zipf.write(ass_filename)\n",
        "\n",
        "    # Trigger the download asynchronously\n",
        "    files.download(zip_filename)\n",
        "\n",
        "  print('第',i+1,'个文件字幕生成完毕/',i+1, 'file(s) was completed!')\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "print('所有字幕生成完毕 All done!')\n",
        "\n",
        "# 如果设定了自动关闭连接，这里将释放Colab资源\n",
        "# disconnect_runtime()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
